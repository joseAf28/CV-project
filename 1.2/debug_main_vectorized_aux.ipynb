{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import src\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keypoints(file_path):\n",
    "    data = loadmat(file_path)\n",
    "    kp = data['kp']  #Keypoints (Nx2 matrix)\n",
    "    desc = data['desc']  # Descritores(NxD matrix)\n",
    "    return kp, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_keypoints_ransac(desc1, desc2, kp1, kp2, threshold=0.25, max_iter=1, inlier_threshold=2.0):\n",
    "    \n",
    "    # calcula a distncia entre os descritores\n",
    "    distances = cdist(desc1, desc2)\n",
    "    matches = []\n",
    "\n",
    "    for i, row in enumerate(distances):\n",
    "        sorted_indices = np.argsort(row)\n",
    "        if row[sorted_indices[0]] < threshold * row[sorted_indices[1]]:\n",
    "            matches.append((i, sorted_indices[0]))\n",
    "\n",
    "    matches = np.array(matches)\n",
    "\n",
    "    \n",
    "    best_inliers = []\n",
    "    best_H = None\n",
    "    \n",
    "    print(\"matches: \", matches.shape)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        print(\"hello\")\n",
    "        #4 matches aleatórios (usar mais?)\n",
    "        sampled_matches = matches[np.random.choice(matches.shape[0], 8, replace=False)]\n",
    "        src_pts = kp1[sampled_matches[:, 0]]\n",
    "        dst_pts = kp2[sampled_matches[:, 1]]\n",
    "\n",
    "        H = src.getPerspectiveTransform(src_pts,dst_pts)\n",
    "        \n",
    "        inliers = []\n",
    "        for match in matches:\n",
    "            pt1 = kp1[match[0]]\n",
    "            pt2 = kp2[match[1]]\n",
    "            \n",
    "            \n",
    "            pt1_hom = np.append(pt1, 1)  \n",
    "            transformed_pt = H @ pt1_hom\n",
    "            transformed_pt /= transformed_pt[2]  \n",
    "            \n",
    "            \n",
    "            dist = np.linalg.norm(transformed_pt[:2] - pt2)\n",
    "            if dist < inlier_threshold:\n",
    "                inliers.append(match)\n",
    "\n",
    "        print(\"inliers: \", inliers)\n",
    "        \n",
    "        # Se o número de inliers for maior que o melhor encontrado, atualizar\n",
    "        if len(inliers) > len(best_inliers):\n",
    "            best_inliers = inliers\n",
    "            best_H = H\n",
    "\n",
    "    return best_inliers, best_H, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMatch:\n",
    "    def __init__(self, _queryIdx, _trainIdx, _distance):\n",
    "        self.queryIdx = _queryIdx\n",
    "        self.trainIdx = _trainIdx\n",
    "        self.distance = _distance\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'DMatch(queryIdx: %s, trainIdx: %s, distance: %s)' % (self.queryIdx, self.trainIdx, self.distance)\n",
    "\n",
    "\n",
    "\n",
    "def knn_match_vectorized(descriptors_query, descriptors_train, k):\n",
    "    distances = scipy.spatial.distance.cdist(descriptors_query, descriptors_train, 'euclidean') ## calculate the distances between each query descriptor and each train descriptor: i -> query, j -> train\n",
    "    indices = np.argsort(distances, axis=1) ## order for each row (query descriptor) the indices of the train descriptors\n",
    "    matches = np.zeros((descriptors_query.shape[0], k), dtype=object)\n",
    "    \n",
    "    for i in range(descriptors_query.shape[0]):\n",
    "        k_nearest_neighbors = [(index, distances[i, index]) for index in indices[i, :k]]\n",
    "        match = np.array([DMatch(_queryIdx=i, _trainIdx=neighbor[0], _distance=neighbor[1]) for neighbor in k_nearest_neighbors])\n",
    "        matches[i, :] = match\n",
    "        \n",
    "    return matches\n",
    "\n",
    "\n",
    "\n",
    "def matching_optional(desc1, desc2, threshold=0.25):\n",
    "    \n",
    "    distances = scipy.spatial.distance.cdist(desc1, desc2, 'euclidean') ## calculate the distances between each query descriptor and each train descriptor: i -> query, j -> train\n",
    "    sorted_indices = np.argsort(distances, axis=1)[:, :2]\n",
    "    \n",
    "    first_min_indices = sorted_indices[:, 0]\n",
    "    second_min_indices = sorted_indices[:, 1]\n",
    "\n",
    "    first_min_distances = distances[np.arange(distances.shape[0]), first_min_indices]\n",
    "    second_min_distances = distances[np.arange(distances.shape[0]), second_min_indices]\n",
    "\n",
    "    condition = first_min_distances < threshold * second_min_distances\n",
    "    matches = np.column_stack((np.where(condition)[0], first_min_indices[condition]))\n",
    "    \n",
    "    return matches\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o mosaico\n",
    "initial_image_path = 'ISRwall/input_1/images/img_0001.jpg'\n",
    "initial_image = src.image_to_matrix(initial_image_path)\n",
    "width, height = (20000,10000)\n",
    "start=2000\n",
    "dst = np.full((height, width, initial_image.shape[2] if initial_image.ndim == 3 else 1), 0, dtype=initial_image.dtype)\n",
    "\n",
    "for y in range(initial_image.shape[0]):\n",
    "    for x in range(initial_image.shape[1]):\n",
    "        if 0 <= x+12000 < width and 0 <= y+6000 < height:\n",
    "            dst[y+6000, x+12000] = initial_image[y, x]\n",
    "\n",
    "src.matrix_to_image(dst, f\"final_mosaic.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kp1:  (6106, 2)\n",
      "desc1:  (6106, 64)\n",
      "kp2:  (6808, 2)\n",
      "desc2:  (6808, 64)\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "kp1, desc1 = load_keypoints(f\"ISRwall/input_1/keypoints/kp_000{counter+1}.mat\")\n",
    "kp2, desc2 = load_keypoints(f\"ISRwall/input_1/keypoints/kp_000{counter+2}.mat\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"kp1: \", kp1.shape)\n",
    "print(\"desc1: \", desc1.shape)\n",
    "print(\"kp2: \", kp2.shape)\n",
    "print(\"desc2: \", desc2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches:  (170, 2)\n",
      "hello\n",
      "inliers:  [array([32,  4]), array([154,  49]), array([279, 134]), array([364, 175]), array([435, 217]), array([443, 121]), array([527, 417]), array([542, 228]), array([807, 430]), array([824, 319]), array([953, 347]), array([986, 421]), array([1050,  512]), array([1070,  488]), array([1081,  443]), array([1152,  824]), array([1273,  603]), array([1319,  687]), array([1433, 1183]), array([1450,  936]), array([1477,  843]), array([1497, 1030]), array([1502,  854]), array([1512,  745]), array([1530,  873]), array([1531,  771]), array([1537,  707]), array([1539, 1043]), array([1630, 1181]), array([1734, 1017]), array([1786, 1274]), array([1842,  840]), array([1963, 1397]), array([2060, 1422]), array([2062, 1265]), array([2074, 1561]), array([2132, 1738]), array([2300, 1799]), array([2397, 1548]), array([2406, 1675]), array([2429, 1656]), array([2528, 2054]), array([2569, 1812]), array([2598, 2376]), array([2638, 2171]), array([2686, 2393]), array([2730, 2049]), array([2878, 2483]), array([2889, 2200]), array([2911, 2656]), array([2913, 2087]), array([3052, 2631]), array([3092, 2801]), array([3198, 2806]), array([3286, 3049]), array([3295, 3230]), array([3436, 2791]), array([3514, 3240]), array([3540, 3772]), array([3558, 3338]), array([3676, 3128]), array([3694, 3514]), array([3724, 3553]), array([3853, 3554]), array([3858, 3620]), array([3933, 3569]), array([3998, 4005]), array([4016, 4573]), array([4137, 4521]), array([4151, 4443]), array([4181, 4894]), array([4349, 4295]), array([4538, 4338]), array([4624, 5100]), array([4647, 4841]), array([4666, 4912]), array([4677, 4367]), array([4689, 4836]), array([4737, 5783]), array([4890, 4970]), array([4956, 5393]), array([5081, 5025]), array([5176, 5241]), array([5606, 6736]), array([5816, 6298])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#matches = match_keypoints(desc1, desc2)\n",
    "\n",
    "inliers_original, H_ransac_original, matches_original = match_keypoints_ransac(desc1, desc2, kp1, kp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches_original:  (170, 2)\n",
      "inliers:  85\n",
      "H_ransac:  [[ 8.06496679e-01 -1.65600742e-01  7.31523669e+02]\n",
      " [-3.23721837e-02  7.73650869e-01  9.26574433e+02]\n",
      " [-2.94897264e-05 -6.40383448e-05  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"matches_original: \", matches_original.shape)\n",
    "print(\"inliers: \", len(inliers_original))\n",
    "print(\"H_ransac: \", H_ransac_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_2 = matching_optional(desc1, desc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inliers:  (18, 2)\n",
      "[[2878 2483]\n",
      " [3143 2804]\n",
      " [3198 2806]\n",
      " [3505 2983]\n",
      " [3724 3553]\n",
      " [4062 3758]\n",
      " [4181 4894]\n",
      " [4521 4365]\n",
      " [4857 4865]\n",
      " [5073 4968]]\n"
     ]
    }
   ],
   "source": [
    "## choice 1\n",
    "inlier_threshold = 2.0\n",
    "sampled_matches = matches_original[np.random.choice(matches_original.shape[0], 4, replace=False)]\n",
    "src_pts = kp1[sampled_matches[:, 0]]\n",
    "dst_pts = kp2[sampled_matches[:, 1]]\n",
    "\n",
    "H = src.getPerspectiveTransform(src_pts,dst_pts)\n",
    "        \n",
    "inliers = []\n",
    "for match in matches_original:\n",
    "    pt1 = kp1[match[0]]\n",
    "    pt2 = kp2[match[1]]\n",
    "            \n",
    "            \n",
    "    pt1_hom = np.append(pt1, 1)  \n",
    "    transformed_pt = H @ pt1_hom\n",
    "    transformed_pt /= transformed_pt[2]  \n",
    "\n",
    "    dist = np.linalg.norm(transformed_pt[:2] - pt2)\n",
    "    if dist < inlier_threshold:\n",
    "        inliers.append(match)\n",
    "\n",
    "inliers_original = np.array(inliers)\n",
    "\n",
    "print(\"inliers: \", inliers_original.shape)\n",
    "print(inliers_original[-10:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.52867529e+03 2.80704980e+03 1.51490808e+03 2.11259399e+03\n",
      "  2.19201953e+03 2.65929443e+03 1.98127258e+03 1.77079089e+03\n",
      "  2.13739819e+03 2.15568701e+03]\n",
      " [1.10878992e+03 1.06965356e+03 8.26793152e+02 8.11127136e+02\n",
      "  8.09396790e+02 1.12781799e+03 8.35782349e+02 1.28695178e+03\n",
      "  1.35662537e+03 1.31542883e+03]\n",
      " [1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]]\n",
      "(170, 2)\n",
      "(170, 2)\n",
      "inliers:  (18, 2)\n",
      "[[2878 2483]\n",
      " [3143 2804]\n",
      " [3198 2806]\n",
      " [3505 2983]\n",
      " [3724 3553]\n",
      " [4062 3758]\n",
      " [4181 4894]\n",
      " [4521 4365]\n",
      " [4857 4865]\n",
      " [5073 4968]]\n"
     ]
    }
   ],
   "source": [
    "### vectorized version of ransac\n",
    "\n",
    "inlier_threshold = 2.0\n",
    "best_inliers = []\n",
    "best_H = None\n",
    "\n",
    "# samples_matches = matches_2[np.random.choice(matches_2.shape[0], 4, replace=False)]\n",
    "\n",
    "H = src.getPerspectiveTransform(kp1[sampled_matches[:, 0]], kp2[sampled_matches[:, 1]])\n",
    "\n",
    "src_pts_hom = np.column_stack((kp1[matches_original[:, 0]], np.ones((matches_original.shape[0], 1)))).T\n",
    "\n",
    "print(src_pts_hom[:, :10])\n",
    "\n",
    "# print(\"src_pts_hom: \", src_pts_hom.shape)\n",
    "# print(\"H: \", H.shape)\n",
    "\n",
    "transformed_pts_hom = (H @ src_pts_hom).T\n",
    "\n",
    "\n",
    "transformed_pts_hom /= transformed_pts_hom[:, 2][:, None]\n",
    "\n",
    "dst_pts_all = kp2[matches_original[:, 1]]\n",
    "\n",
    "print(transformed_pts_hom[:, :2].shape)\n",
    "print(dst_pts_all.shape)\n",
    "\n",
    "dists = np.linalg.norm(transformed_pts_hom[:, :2] - dst_pts_all, axis=1)\n",
    "\n",
    "inliers_2 = matches_original[dists < inlier_threshold]\n",
    "\n",
    "print(\"inliers: \", inliers_2.shape)\n",
    "print(inliers_2[-10:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
